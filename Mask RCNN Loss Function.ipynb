{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def compose_image_meta：meta = np.array([image_id] + list(image_shape) + list(window) + list(active_class_ids))\n",
    "#一张图是这样一行？\n",
    "active_class_ids: \n",
    "List of class_ids available in the dataset from whichthe image came. \n",
    "Useful if training on images from multiple datasetswhere not all classes are present in all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class DetectionTargetLayer(KE.Layer):\n",
    "Inputs:\n",
    "    proposals: [batch, N, (y1, x1, y2, x2)] in normalized coordinates. Might\n",
    "               be zero padded if there are not enough proposals.\n",
    "    gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs.\n",
    "    gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)] in normalized\n",
    "              coordinates.\n",
    "    gt_masks: [batch, height, width, MAX_GT_INSTANCES] of boolean type\n",
    "Returns: Target ROIs and corresponding class IDs, bounding box shifts,and masks.\n",
    "    rois: [batch, TRAIN_ROIS_PER_IMAGE, (y1, x1, y2, x2)] in normalized\n",
    "          coordinates\n",
    "    target_class_ids: [batch, TRAIN_ROIS_PER_IMAGE]. Integer class IDs.\n",
    "    target_deltas: [batch, TRAIN_ROIS_PER_IMAGE, NUM_CLASSES,\n",
    "                    (dy, dx, log(dh), log(dw), class_id)]\n",
    "                   Class-specific bbox refinments.\n",
    "    target_mask: [batch, TRAIN_ROIS_PER_IMAGE, height, width)\n",
    "                 Masks cropped to bbox boundaries and resized to neural\n",
    "                 network output size.\n",
    "Note: Returned arrays might be zero padded if not enough target ROIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def load_image_gt(dataset, config, image_id, augment=False,\n",
    "                  use_mini_mask=False):\n",
    "    \"\"\"Load and return ground truth data for an image (image, mask, bounding boxes).\n",
    "  Returns:\n",
    "    image: [height, width, 3]\n",
    "    shape: the original shape of the image before resizing and cropping.\n",
    "    class_ids: [instance_count] Integer class IDs\n",
    "    bbox: [instance_count, (y1, x1, y2, x2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Detection GT (class IDs, bounding boxes, and masks)\n",
    "            # 1. GT Class IDs (zero padded)\n",
    "            input_gt_class_ids = KL.Input(\n",
    "                shape=[None], name=\"input_gt_class_ids\", dtype=tf.int32)\n",
    "            # 2. GT Boxes in pixels (zero padded)\n",
    "            # [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)] in image coordinates\n",
    "            input_gt_boxes = KL.Input(\n",
    "                shape=[None, 4], name=\"input_gt_boxes\", dtype=tf.float32)\n",
    "            # Normalize coordinates\n",
    "            h, w = K.shape(input_image)[1], K.shape(input_image)[2]\n",
    "            image_scale = K.cast(K.stack([h, w, h, w], axis=0), tf.float32)\n",
    "            gt_boxes = KL.Lambda(lambda x: x / image_scale)(input_gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    \"\"\"Implements Smooth-L1 loss.\n",
    "    y_true and y_pred are typicallly: [N, 4], but could be any shape.\n",
    "    \"\"\"\n",
    "    diff = K.abs(y_true - y_pred)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "    return loss\n",
    "def mrcnn_class_loss_graph(target_class_ids, pred_class_logits,\n",
    "                           active_class_ids):\n",
    "    \"\"\"Loss for the classifier head of Mask RCNN.\n",
    "    target_class_ids: [batch, num_rois]. Integer class IDs. Uses zero\n",
    "        padding to fill in the array.\n",
    "    pred_class_logits: [batch, num_rois, num_classes]\n",
    "    active_class_ids: [batch, num_classes]. Has a value of 1 for\n",
    "        classes that are in the dataset of the image, and 0\n",
    "        for classes that are not in the dataset.\n",
    "    \"\"\"\n",
    "    target_class_ids = tf.cast(target_class_ids, 'int64')\n",
    "\n",
    "    # Find predictions of classes that are not in the dataset.\n",
    "    pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "    # TODO: Update this line to work with batch > 1. Right now it assumes all\n",
    "    #       images in a batch have the same active_class_ids\n",
    "    pred_active = tf.gather(active_class_ids[0], pred_class_ids)\n",
    "#tf.gather(list,indices)根据后者提取前者中相应位置的数据\n",
    "    # Loss\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=target_class_ids, logits=pred_class_logits)\n",
    "\n",
    "    # Erase losses of predictions of classes that are not in the active\n",
    "    # classes of the image.\n",
    "    loss = loss * pred_active\n",
    "\n",
    "    # Computer loss mean. Use only predictions that contribute\n",
    "    # to the loss to get a correct mean.\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrcnn_bbox_loss_graph(target_bbox, target_class_ids, pred_bbox):\n",
    "    \"\"\"Loss for Mask R-CNN bounding box refinement.\n",
    "    target_bbox: [batch, num_rois, (dy, dx, log(dh), log(dw))]\n",
    "    target_class_ids: [batch, num_rois]. Integer class IDs.\n",
    "    pred_bbox: [batch, num_rois, num_classes, (dy, dx, log(dh), log(dw))]\n",
    "    \"\"\"\n",
    "    # Reshape to merge batch and roi dimensions for simplicity.\n",
    "    target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "    target_bbox = K.reshape(target_bbox, (-1, 4))\n",
    "    pred_bbox = K.reshape(pred_bbox, (-1, K.int_shape(pred_bbox)[2], 4))\n",
    "\n",
    "    # Only positive ROIs contribute to the loss. And only\n",
    "    # the right class_id of each ROI. Get their indicies.\n",
    "    positive_roi_ix = tf.where(target_class_ids > 0)[:, 0]\n",
    "    positive_roi_class_ids = tf.cast(\n",
    "        tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "    indices = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "\n",
    "    # Gather the deltas (predicted and true) that contribute to loss\n",
    "    target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "    pred_bbox = tf.gather_nd(pred_bbox, indices)\n",
    "\n",
    "    # Smooth-L1 Loss\n",
    "    loss = K.switch(tf.size(target_bbox) > 0,\n",
    "                    smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "                    tf.constant(0.0))\n",
    "    loss = K.mean(loss)\n",
    "    loss = K.reshape(loss, [1, 1])\n",
    "    return loss\n",
    "\n",
    "# Losses\n",
    "            rpn_class_loss = KL.Lambda(lambda x: rpn_class_loss_graph(*x), name=\"rpn_class_loss\")(\n",
    "                [input_rpn_match, rpn_class_logits])\n",
    "            rpn_bbox_loss = KL.Lambda(lambda x: rpn_bbox_loss_graph(config, *x), name=\"rpn_bbox_loss\")(\n",
    "                [input_rpn_bbox, input_rpn_match, rpn_bbox])\n",
    "            class_loss = KL.Lambda(lambda x: mrcnn_class_loss_graph(*x), name=\"mrcnn_class_loss\")(\n",
    "                [target_class_ids, mrcnn_class_logits, active_class_ids])\n",
    "            bbox_loss = KL.Lambda(lambda x: mrcnn_bbox_loss_graph(*x), name=\"mrcnn_bbox_loss\")(\n",
    "                [target_bbox, target_class_ids, mrcnn_bbox])\n",
    "            mask_loss = KL.Lambda(lambda x: mrcnn_mask_loss_graph(*x), name=\"mrcnn_mask_loss\")(\n",
    "                [target_mask, target_class_ids, mrcnn_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_detection_targets(rpn_rois, gt_class_ids, gt_boxes, gt_masks, config):\n",
    "    \"\"\"Generate targets for training Stage 2 classifier and mask heads.\n",
    "    This is not used in normal training. It's useful for debugging or to train\n",
    "    the Mask RCNN heads without using the RPN head.\n",
    "    Inputs:\n",
    "    rpn_rois: [N, (y1, x1, y2, x2)] proposal boxes.\n",
    "    gt_class_ids: [instance count] Integer class IDs\n",
    "    gt_boxes: [instance count, (y1, x1, y2, x2)]\n",
    "    gt_masks: [height, width, instance count] Grund truth masks. Can be full\n",
    "              size or mini-masks.\n",
    "    Returns:\n",
    "    rois: [TRAIN_ROIS_PER_IMAGE, (y1, x1, y2, x2)]\n",
    "    class_ids: [TRAIN_ROIS_PER_IMAGE]. Integer class IDs.\n",
    "    bboxes: [TRAIN_ROIS_PER_IMAGE, NUM_CLASSES, (y, x, log(h), log(w))]. Class-specific\n",
    "            bbox refinments.\n",
    "    masks: [TRAIN_ROIS_PER_IMAGE, height, width, NUM_CLASSES). Class specific masks cropped\n",
    "           to bbox boundaries and resized to neural network output size.\n",
    "    \"\"\"\n",
    "    assert rpn_rois.shape[0] > 0\n",
    "    assert gt_class_ids.dtype == np.int32, \"Expected int but got {}\".format(\n",
    "        gt_class_ids.dtype)\n",
    "    assert gt_boxes.dtype == np.int32, \"Expected int but got {}\".format(\n",
    "        gt_boxes.dtype)\n",
    "    assert gt_masks.dtype == np.bool_, \"Expected bool but got {}\".format(\n",
    "        gt_masks.dtype)\n",
    "\n",
    "    # It's common to add GT Boxes to ROIs but we don't do that here because\n",
    "    # according to XinLei Chen's paper, it doesn't help.\n",
    "\n",
    "    # Trim empty padding in gt_boxes and gt_masks parts\n",
    "    instance_ids = np.where(gt_class_ids > 0)[0]\n",
    "    assert instance_ids.shape[0] > 0, \"Image must contain instances.\"\n",
    "    gt_class_ids = gt_class_ids[instance_ids]\n",
    "    gt_boxes = gt_boxes[instance_ids]\n",
    "    gt_masks = gt_masks[:, :, instance_ids]\n",
    "\n",
    "    # Compute areas of ROIs and ground truth boxes.\n",
    "    rpn_roi_area = (rpn_rois[:, 2] - rpn_rois[:, 0]) * \\\n",
    "        (rpn_rois[:, 3] - rpn_rois[:, 1])\n",
    "    gt_box_area = (gt_boxes[:, 2] - gt_boxes[:, 0]) * \\\n",
    "        (gt_boxes[:, 3] - gt_boxes[:, 1])\n",
    "\n",
    "    # Compute overlaps [rpn_rois, gt_boxes]\n",
    "    overlaps = np.zeros((rpn_rois.shape[0], gt_boxes.shape[0]))\n",
    "    for i in range(overlaps.shape[1]):\n",
    "        gt = gt_boxes[i]\n",
    "        overlaps[:, i] = utils.compute_iou(\n",
    "            gt, rpn_rois, gt_box_area[i], rpn_roi_area)\n",
    "\n",
    "    # Assign ROIs to GT boxes\n",
    "    rpn_roi_iou_argmax = np.argmax(overlaps, axis=1)\n",
    "    rpn_roi_iou_max = overlaps[np.arange(\n",
    "        overlaps.shape[0]), rpn_roi_iou_argmax]\n",
    "    # GT box assigned to each ROI\n",
    "    rpn_roi_gt_boxes = gt_boxes[rpn_roi_iou_argmax]\n",
    "    rpn_roi_gt_class_ids = gt_class_ids[rpn_roi_iou_argmax]\n",
    "\n",
    "    # Positive ROIs are those with >= 0.5 IoU with a GT box.\n",
    "    fg_ids = np.where(rpn_roi_iou_max > 0.5)[0]\n",
    "\n",
    "    # Negative ROIs are those with max IoU 0.1-0.5 (hard example mining)\n",
    "    # TODO: To hard example mine or not to hard example mine, that's the question\n",
    "#     bg_ids = np.where((rpn_roi_iou_max >= 0.1) & (rpn_roi_iou_max < 0.5))[0]\n",
    "    bg_ids = np.where(rpn_roi_iou_max < 0.5)[0]\n",
    "\n",
    "    # Subsample ROIs. Aim for 33% foreground.\n",
    "    # FG\n",
    "    fg_roi_count = int(config.TRAIN_ROIS_PER_IMAGE * config.ROI_POSITIVE_RATIO)\n",
    "    if fg_ids.shape[0] > fg_roi_count:\n",
    "        keep_fg_ids = np.random.choice(fg_ids, fg_roi_count, replace=False)\n",
    "    else:\n",
    "        keep_fg_ids = fg_ids\n",
    "    # BG\n",
    "    remaining = config.TRAIN_ROIS_PER_IMAGE - keep_fg_ids.shape[0]\n",
    "    if bg_ids.shape[0] > remaining:\n",
    "        keep_bg_ids = np.random.choice(bg_ids, remaining, replace=False)\n",
    "    else:\n",
    "        keep_bg_ids = bg_ids\n",
    "    # Combine indicies of ROIs to keep\n",
    "    keep = np.concatenate([keep_fg_ids, keep_bg_ids])\n",
    "    # Need more?\n",
    "    remaining = config.TRAIN_ROIS_PER_IMAGE - keep.shape[0]\n",
    "    if remaining > 0:\n",
    "        # Looks like we don't have enough samples to maintain the desired\n",
    "        # balance. Reduce requirements and fill in the rest. This is\n",
    "        # likely different from the Mask RCNN paper.\n",
    "\n",
    "        # There is a small chance we have neither fg nor bg samples.\n",
    "        if keep.shape[0] == 0:\n",
    "            # Pick bg regions with easier IoU threshold\n",
    "            bg_ids = np.where(rpn_roi_iou_max < 0.5)[0]\n",
    "            assert bg_ids.shape[0] >= remaining\n",
    "            keep_bg_ids = np.random.choice(bg_ids, remaining, replace=False)\n",
    "            assert keep_bg_ids.shape[0] == remaining\n",
    "            keep = np.concatenate([keep, keep_bg_ids])\n",
    "        else:\n",
    "            # Fill the rest with repeated bg rois.\n",
    "            keep_extra_ids = np.random.choice(\n",
    "                keep_bg_ids, remaining, replace=True)\n",
    "            keep = np.concatenate([keep, keep_extra_ids])\n",
    "    assert keep.shape[0] == config.TRAIN_ROIS_PER_IMAGE, \\\n",
    "        \"keep doesn't match ROI batch size {}, {}\".format(\n",
    "            keep.shape[0], config.TRAIN_ROIS_PER_IMAGE)\n",
    "\n",
    "    # Reset the gt boxes assigned to BG ROIs.\n",
    "    rpn_roi_gt_boxes[keep_bg_ids, :] = 0\n",
    "    rpn_roi_gt_class_ids[keep_bg_ids] = 0\n",
    "\n",
    "    # For each kept ROI, assign a class_id, and for FG ROIs also add bbox refinement.\n",
    "    rois = rpn_rois[keep]\n",
    "    roi_gt_boxes = rpn_roi_gt_boxes[keep]\n",
    "    roi_gt_class_ids = rpn_roi_gt_class_ids[keep]\n",
    "    roi_gt_assignment = rpn_roi_iou_argmax[keep]\n",
    "\n",
    "    # Class-aware bbox deltas. [y, x, log(h), log(w)]\n",
    "    bboxes = np.zeros((config.TRAIN_ROIS_PER_IMAGE,\n",
    "                       config.NUM_CLASSES, 4), dtype=np.float32)\n",
    "    pos_ids = np.where(roi_gt_class_ids > 0)[0]\n",
    "    bboxes[pos_ids, roi_gt_class_ids[pos_ids]] = utils.box_refinement(\n",
    "        rois[pos_ids], roi_gt_boxes[pos_ids, :4])\n",
    "    # Normalize bbox refinments\n",
    "    bboxes /= config.BBOX_STD_DEV\n",
    "\n",
    "    # Generate class-specific target masks.\n",
    "    masks = np.zeros((config.TRAIN_ROIS_PER_IMAGE, config.MASK_SHAPE[0], config.MASK_SHAPE[1], config.NUM_CLASSES),\n",
    "                     dtype=np.float32)\n",
    "    for i in pos_ids:\n",
    "        class_id = roi_gt_class_ids[i]\n",
    "        assert class_id > 0, \"class id must be greater than 0\"\n",
    "        gt_id = roi_gt_assignment[i]\n",
    "        class_mask = gt_masks[:, :, gt_id]\n",
    "\n",
    "        if config.USE_MINI_MASK:\n",
    "            # Create a mask placeholder, the size of the image\n",
    "            placeholder = np.zeros(config.IMAGE_SHAPE[:2], dtype=bool)\n",
    "            # GT box\n",
    "            gt_y1, gt_x1, gt_y2, gt_x2 = gt_boxes[gt_id]\n",
    "            gt_w = gt_x2 - gt_x1\n",
    "            gt_h = gt_y2 - gt_y1\n",
    "            # Resize mini mask to size of GT box\n",
    "            placeholder[gt_y1:gt_y2, gt_x1:gt_x2] = \\\n",
    "                np.round(scipy.misc.imresize(class_mask.astype(float), (gt_h, gt_w),\n",
    "                                             interp='nearest') / 255.0).astype(bool)\n",
    "            # Place the mini batch in the placeholder\n",
    "            class_mask = placeholder\n",
    "\n",
    "        # Pick part of the mask and resize it\n",
    "        y1, x1, y2, x2 = rois[i].astype(np.int32)\n",
    "        m = class_mask[y1:y2, x1:x2]\n",
    "        mask = scipy.misc.imresize(\n",
    "            m.astype(float), config.MASK_SHAPE, interp='nearest') / 255.0\n",
    "        masks[i, :, :, class_id] = mask\n",
    "\n",
    "    return rois, roi_gt_class_ids, bboxes, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_generator\n",
    "根据batch size做dataset的生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, config, shuffle=True, augment=True, random_rois=0,\n",
    "                   batch_size=1, detection_targets=False):\n",
    "    '''A generator that returns images and corresponding target class ids,\n",
    "    bounding box deltas, and masks.\n",
    " Returns a Python generator. Upon calling next() on it, the\n",
    "    generator returns two lists, inputs and outputs. The containtes\n",
    "    of the lists differs depending on the received arguments:\n",
    "    inputs list:\n",
    "    - images: [batch, H, W, C]\n",
    "    - image_meta: [batch, size of image meta]\n",
    "    - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)\n",
    "    - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.\n",
    "    - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs\n",
    "    - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]\n",
    "    - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width\n",
    "                are those of the image unless use_mini_mask is True, in which\n",
    "                case they are defined in MINI_MASK_SHAPE.\n",
    "    outputs list: Usually empty in regular training. But if detection_targets\n",
    "        is True then the outputs list contains target class_ids, bbox deltas,\n",
    "        and masks.'''\n",
    "     b = 0  # batch item index\n",
    "    image_index = -1\n",
    "    image_ids = np.copy(dataset.image_ids)\n",
    "    error_count = 0\n",
    "        while True:\n",
    "        try:\n",
    "            # Increment index to pick next image. Shuffle if at the start of an epoch.\n",
    "            image_index = (image_index + 1) % len(image_ids)\n",
    "            if shuffle and image_index == 0:\n",
    "                np.random.shuffle(image_ids)\n",
    "\n",
    "            # Get GT bounding boxes and masks for image.\n",
    "            image_id = image_ids[image_index]\n",
    "            image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                load_image_gt(dataset, config, image_id, augment=augment,\n",
    "                              use_mini_mask=config.USE_MINI_MASK)\n",
    "            # Mask R-CNN Targets\n",
    "            if random_rois:\n",
    "                rpn_rois = generate_random_rois(\n",
    "                    image.shape, random_rois, gt_class_ids, gt_boxes)\n",
    "                if detection_targets:\n",
    "                    rois, mrcnn_class_ids, mrcnn_bbox, mrcnn_mask =\\\n",
    "                        build_detection_targets(\n",
    "                            rpn_rois, gt_class_ids, gt_boxes, gt_masks, config)\n",
    "                        \n",
    "if b >= batch_size:\n",
    "                inputs = [batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox,\n",
    "                          batch_gt_class_ids, batch_gt_boxes, batch_gt_masks]\n",
    "                outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # RPN Model\n",
    "        rpn = build_rpn_model(config.RPN_ANCHOR_STRIDE,len(config.RPN_ANCHOR_RATIOS), 256)\n",
    "        # Loop through pyramid layers\n",
    "        layer_outputs = []  # list of lists\n",
    "        for p in rpn_feature_maps:\n",
    "            layer_outputs.append(rpn([p]))\n",
    "        # Concatenate layer outputs\n",
    "        # Convert from list of lists of level outputs to list of lists of outputs across levels.\n",
    "        # e.g. [[a1, b1, c1], [a2, b2, c2]] => [[a1, a2], [b1, b2], [c1, c2]]\n",
    "        output_names = [\"rpn_class_logits\", \"rpn_class\", \"rpn_bbox\"]\n",
    "        outputs = list(zip(*layer_outputs))\n",
    "        outputs = [KL.Concatenate(axis=1, name=n)(list(o)) for o, n in zip(outputs, output_names)]\n",
    "\n",
    "        rpn_class_logits, rpn_class, rpn_bbox = outputs\n",
    "\n",
    "        # Generate proposals\n",
    "        # Proposals are [batch, N, (y1, x1, y2, x2)] in normalized coordinates\n",
    "        # and zero padded.\n",
    "        proposal_count = config.POST_NMS_ROIS_TRAINING if mode == \"training\"\\\n",
    "            else config.POST_NMS_ROIS_INFERENCE\n",
    "        rpn_rois = ProposalLayer(proposal_count=proposal_count,\n",
    "                                 nms_threshold=config.RPN_NMS_THRESHOLD,\n",
    "                                 name=\"ROI\",\n",
    "                                 anchors=self.anchors,\n",
    "                                 config=config)([rpn_class, rpn_bbox])\n",
    "\n",
    "        if mode == \"training\":\n",
    "            # Class ID mask to mark class IDs supported by the dataset the image\n",
    "            # came from.\n",
    "            _, _, _, active_class_ids = KL.Lambda(lambda x: parse_image_meta_graph(x),\n",
    "                                                  mask=[None, None, None, None])(input_image_meta)\n",
    "\n",
    "            if not config.USE_RPN_ROIS:\n",
    "                # Ignore predicted ROIs and use ROIs provided as an input.\n",
    "                input_rois = KL.Input(shape=[config.POST_NMS_ROIS_TRAINING, 4],\n",
    "                                      name=\"input_roi\", dtype=np.int32)\n",
    "                # Normalize coordinates to 0-1 range.\n",
    "                target_rois = KL.Lambda(lambda x: K.cast(\n",
    "                    x, tf.float32) / image_scale[:4])(input_rois)\n",
    "            else:\n",
    "                target_rois = rpn_rois\n",
    "\n",
    "            # Generate detection targets\n",
    "            # Subsamples proposals and generates target outputs for training\n",
    "            # Note that proposal class IDs, gt_boxes, and gt_masks are zero\n",
    "            # padded. Equally, returned rois and targets are zero padded.\n",
    "            rois, target_class_ids, target_bbox, target_mask =\\\n",
    "                DetectionTargetLayer(config, name=\"proposal_targets\")([\n",
    "                    target_rois, input_gt_class_ids, gt_boxes, input_gt_masks])\n",
    "\n",
    "            # Network Heads\n",
    "            # TODO: verify that this handles zero padded ROIs\n",
    "            mrcnn_class_logits, mrcnn_class, mrcnn_bbox =\\\n",
    "                fpn_classifier_graph(rois, mrcnn_feature_maps, config.IMAGE_SHAPE,\n",
    "                                     config.POOL_SIZE, config.NUM_CLASSES)\n",
    "\n",
    "            mrcnn_mask = build_fpn_mask_graph(rois, mrcnn_feature_maps,\n",
    "                                              config.IMAGE_SHAPE,\n",
    "                                              config.MASK_POOL_SIZE,\n",
    "                                              config.NUM_CLASSES)\n",
    "\n",
    "            # TODO: clean up (use tf.identify if necessary)\n",
    "            output_rois = KL.Lambda(lambda x: x * 1, name=\"output_rois\")(rois)\n",
    "\n",
    "            # Losses\n",
    "            rpn_class_loss = KL.Lambda(lambda x: rpn_class_loss_graph(*x), name=\"rpn_class_loss\")(\n",
    "                [input_rpn_match, rpn_class_logits])\n",
    "            rpn_bbox_loss = KL.Lambda(lambda x: rpn_bbox_loss_graph(config, *x), name=\"rpn_bbox_loss\")(\n",
    "                [input_rpn_bbox, input_rpn_match, rpn_bbox])\n",
    "            class_loss = KL.Lambda(lambda x: mrcnn_class_loss_graph(*x), name=\"mrcnn_class_loss\")(\n",
    "                [target_class_ids, mrcnn_class_logits, active_class_ids])\n",
    "            bbox_loss = KL.Lambda(lambda x: mrcnn_bbox_loss_graph(*x), name=\"mrcnn_bbox_loss\")(\n",
    "                [target_bbox, target_class_ids, mrcnn_bbox])\n",
    "            mask_loss = KL.Lambda(lambda x: mrcnn_mask_loss_graph(*x), name=\"mrcnn_mask_loss\")(\n",
    "                [target_mask, target_class_ids, mrcnn_mask])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
